{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\townsend\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "ps = PorterStemmer()\n",
    "df = pd.read_csv('./Restaurant_Reviews.tsv', sep = '\\t', quoting = 3)\n",
    "review = 'I do love this restaurant so much'\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,\n",
       " array(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you',\n",
       "        \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself',\n",
       "        'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n",
       "        'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
       "        'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
       "        'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
       "        'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
       "        'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
       "        'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
       "        'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
       "        'through', 'during', 'before', 'after', 'above', 'below', 'to',\n",
       "        'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
       "        'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
       "        'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
       "        'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
       "        'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will',\n",
       "        'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
       "        'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n",
       "        \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\",\n",
       "        'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma',\n",
       "        'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
       "        'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\",\n",
       "        'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"],\n",
       "       dtype='<U10'))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords), np.array(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144,\n",
       " array(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you',\n",
       "        \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself',\n",
       "        'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n",
       "        'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
       "        'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
       "        'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
       "        'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
       "        'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
       "        'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
       "        'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
       "        'through', 'during', 'before', 'after', 'above', 'below', 'to',\n",
       "        'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
       "        'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
       "        'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
       "        'most', 'other', 'some', 'such', 'nor', 'only', 'own', 'same',\n",
       "        'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just',\n",
       "        'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y',\n",
       "        'ain', 'aren', 'ma', 'mightn', 'won'], dtype='<U10'))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_exceptions = ('no', 'not', 'don', 'don\\'t', 'aren\\'t', 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \"won't\", 'wouldn', \"wouldn't\")\n",
    "\n",
    "stopwords = [a for a in stopwords if a not in stopwords_exceptions]\n",
    "len(stopwords), np.array(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             Wow... Loved this place.\n",
       "1                                   Crust is not good.\n",
       "2            Not tasty and the texture was just nasty.\n",
       "3    Stopped by during the late May bank holiday of...\n",
       "4    The selection on the menu was great and so wer...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       wow love place\n",
       "1                                       crust not good\n",
       "2                               not tasti textur nasti\n",
       "3    stop late may bank holiday rick steve recommen...\n",
       "4                              select menu great price\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = re.sub('[^A-Za-z]', ' ', review)\n",
    "fun = lambda x: ' '.join(ps.stem(a) for a in re.sub('[^a-z]', ' ', x.lower()).split() if a not in stopwords)\n",
    "df['Review'] = df['Review'].apply(fun)\n",
    "\n",
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5573"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer().fit_transform(df['Review'].values).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 5500)\n",
    "X = cv.fit_transform(df['Review'].values).toarray()\n",
    "y = df['Liked'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = ' '.join(ps.stem(a) for a in re.sub('^a-z', ' ', review).split() if a not in stopwords)\n",
    "review = cv.transform([review]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Predict</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC (sigmoid)</th>\n",
       "      <td>80.4%</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>80.0%</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC (rbf)</th>\n",
       "      <td>80.0%</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC (Linear)</th>\n",
       "      <td>79.2%</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>78.0%</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>73.6%</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-NN</th>\n",
       "      <td>70.8%</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GauusianNB</th>\n",
       "      <td>68.8%</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC (poly)</th>\n",
       "      <td>55.6%</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Score  Predict  Correct\n",
       "SVC (sigmoid)        80.4%        1     True\n",
       "Logistic Regression  80.0%        1     True\n",
       "SVC (rbf)            80.0%        1     True\n",
       "SVC (Linear)         79.2%        1     True\n",
       "Random Forest        78.0%        1     True\n",
       "Decision Tree        73.6%        0    False\n",
       "K-NN                 70.8%        1     True\n",
       "GauusianNB           68.8%        1     True\n",
       "SVC (poly)           55.6%        1     True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "models = {'Logistic Regression': LogisticRegression(), 'K-NN': KNeighborsClassifier,\n",
    "'SVC (Linear)': SVC(kernel = 'linear'), 'SVC (rbf)': SVC(kernel = 'rbf'), 'SVC (poly)': SVC(kernel = 'poly'),\n",
    "'SVC (sigmoid)': SVC(kernel = 'sigmoid'), 'GauusianNB': GaussianNB(),\n",
    "'Random Forest': RandomForestClassifier(), 'Decision Tree': DecisionTreeClassifier(criterion = 'entropy')} \n",
    "\n",
    "results = pd.DataFrame(columns = ['Score', 'Predict', 'Correct'])\n",
    "\n",
    "for modelName in models:\n",
    "    Score = 0\n",
    "    \n",
    "    if modelName == 'K-NN':\n",
    "        \n",
    "        for a in range(1, 50):\n",
    "            model = models[modelName](a)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            if model.score(X_test, y_test) > Score:\n",
    "                Score = model.fit(X_train, y_train).score(X_test, y_test)\n",
    "                Predict = model.fit(X, y).predict(review)[0]\n",
    "                Correct = Predict == 1\n",
    "                \n",
    "    else:\n",
    "        Score = models[modelName].fit(X_train, y_train).score(X_test, y_test)\n",
    "        Predict = models[modelName].fit(X, y).predict(review)[0]\n",
    "        Correct = Predict == 1\n",
    "    \n",
    "    results.loc[modelName] = dict(Score = f'{round(Score * 100, 2)}%', Predict = Predict, Correct = Correct)\n",
    "    \n",
    "results.sort_values('Score', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
